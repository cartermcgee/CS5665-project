{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# CODE ADAPTED FROM HW3\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Load the data**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/predict-volcanic-eruptions-ingv-oe/train.csv\")\ntrain.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   segment_id  time_to_eruption\n0  1136037770          12262005\n1  1969647810          32739612\n2  1895879680          14965999\n3  2068207140          26469720\n4   192955606          31072429","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>segment_id</th>\n      <th>time_to_eruption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1136037770</td>\n      <td>12262005</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1969647810</td>\n      <td>32739612</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1895879680</td>\n      <td>14965999</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2068207140</td>\n      <td>26469720</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>192955606</td>\n      <td>31072429</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = \"../input/predict-volcanic-eruptions-ingv-oe/train/\"\ntest_dir = \"../input/predict-volcanic-eruptions-ingv-oe/test/\"","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_csv(index):\n    train1 = pd.read_csv(train_dir + str(train.segment_id.iloc[index]) + \".csv\")\n    train1['timetoerupt'] = train.time_to_eruption.iloc[index]\n    for feat in train1.drop('timetoerupt',1).columns:\n        train1[feat] = train1[feat].mean()\n    train1 = train1.sample(1)\n    return (train1)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add all the training data sets into one dataframe\ndata = pd.DataFrame()\nfor idx in range(train.shape[0]):\n    df = read_csv(idx)\n    data=pd.concat([df,data])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace null values with the mean value\nfor feat in data:\n    data[feat] = data[feat].replace(np.nan, data[feat].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print training data\nprint(data.shape)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare submission document\nsub = pd.read_csv(\"../input/predict-volcanic-eruptions-ingv-oe/sample_submission.csv\")\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_csv(index):\n    test1 = pd.read_csv(test_dir + str(sub.segment_id.iloc[index]) + \".csv\")\n    for feat in test1.columns:\n        test1[feat] = test1[feat].mean()\n    test1 = test1.sample(1)    \n    return (test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.DataFrame()\nfor idx in range(sub.shape[0]):\n    df = read_csv(idx)\n    test = pd.concat([df,test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace null values with mean, same as the training data\nfor feat in test:\n    test[feat] = test[feat].replace(np.nan, test[feat].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print test data\nprint(test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_features = pd.concat((data.iloc[:, 1:-1], test.iloc[:, 1:]))\nall_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_train = data.shape[0]\ntrain_features = all_features[:n_train].values.astype(float)\ntest_features = all_features[n_train:].values.astype(float)\ntrain_labels = data.timetoerupt.values.astype(float).reshape((-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nclass VolcanicEruptionDataset(Dataset):\n    def __init__(self, train_features, train_labels):\n        super().__init__()\n        self.train_features = train_features\n        self.train_labels = train_labels\n\n    def __len__(self):\n        return len(self.train_features)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        return (self.train_features[idx], self.train_labels[idx])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Linear NN Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch import nn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, input_dim, hidden_dim=2, output_dim=1):\n        super().__init__()\n        self.linear1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.linear2 = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        y_pred = self.linear1(x)\n        y_pred = self.relu(y_pred) # ReLU activation\n        y_pred = self.linear2(y_pred)\n        return y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Log_RMSELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mse = nn.MSELoss()\n\n        \n    def forward(self, yhat, y):\n        ## Note: To further stabilize the value when the logarithm is taken, set the value of yhat less than 1 as 1.\n        clipped_preds = torch.clamp(yhat, 1, float('inf'))\n        return torch.sqrt(self.mse(torch.log(clipped_preds), torch.log(y)))\n\n\ncriterion = Log_RMSELoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(net, train_features, train_labels, test_features, test_labels,\n          num_epochs, learning_rate, batch_size):\n    train_ls, test_ls = [], []\n    train_dataset = VolcanicEruptionDataset(train_features, train_labels)\n    train_iter = DataLoader(train_dataset, batch_size, shuffle=True)\n    # The Adam optimization algorithm is used here.\n    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n    #criterion = nn.MSELoss()\n    criterion = Log_RMSELoss()\n    \n    for epoch in range(num_epochs):\n        for X, y in train_iter:\n            yhat = net(X.float())\n            loss = criterion(yhat, y.float())\n\n            # Backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n        train_ls.append(loss)\n        if test_labels is not None:\n            test_ls.append(loss)\n    return train_ls, test_ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_k_fold_data(k, i, X, y):\n    assert k > 1\n    fold_size = X.shape[0] // k\n    X_train, y_train = None, None\n    for j in range(k):\n        idx = slice(j * fold_size, (j + 1) * fold_size)\n        X_part, y_part = X[idx, :], y[idx]\n        if j == i:\n            X_valid, y_valid = X_part, y_part\n        elif X_train is None:\n            X_train, y_train = X_part, y_part\n        else:\n            X_train = np.concatenate((X_train, X_part), axis=0)\n            y_train = np.concatenate((y_train, y_part), axis=0)\n    return X_train, y_train, X_valid, y_valid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## util function\nfrom matplotlib import pyplot as plt\nfrom IPython import display\n\ndef semilogy(x_vals, y_vals, x_label, y_label, x2_vals=None, y2_vals=None,\n             legend=None, figsize=(3.5, 2.5)):\n    \"\"\"Plot x and log(y).\"\"\"\n\n    def set_figsize(figsize=(3.5, 2.5)):\n        \"\"\"Set matplotlib figure size.\"\"\"\n        display.set_matplotlib_formats('svg')\n        plt.rcParams['figure.figsize'] = figsize\n\n    set_figsize(figsize)\n    plt.xlabel(x_label)\n    plt.ylabel(y_label)\n    plt.semilogy(x_vals, y_vals)\n    if x2_vals and y2_vals:\n        plt.semilogy(x2_vals, y2_vals, linestyle=':')\n        plt.legend(legend)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def k_fold(k, X_train, y_train, num_epochs,\n           learning_rate, batch_size):\n    train_l_sum, valid_l_sum = 0, 0\n    for i in range(k):\n        data = get_k_fold_data(k, i, X_train, y_train)\n        net = MLP(all_features.shape[1])\n        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,\n                                   batch_size)\n        train_l_sum += train_ls[-1]\n        valid_l_sum += valid_ls[-1]\n        if i == 0:\n            semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'mse',\n                        range(1, num_epochs + 1), valid_ls,\n                        ['train', 'valid'])\n        print('fold %d, train mse: %f, valid mse: %f' % (\n            i, train_ls[-1], valid_ls[-1]))\n    return train_l_sum / k, valid_l_sum / k","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k, num_epochs, lr, batch_size = 5, 64, 0.001, 64\ntrain_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr, batch_size)\nprint('%d-fold validation: avg train rmse: %f, avg valid rmse: %f'\n      % (k, train_l, valid_l))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_and_pred(train_features, test_feature, train_labels, test_data,\n                   num_epochs, lr, batch_size):\n    net = MLP(all_features.shape[1])\n    train_ls, _ = train(net, train_features, train_labels, None, None,\n                        num_epochs, lr, batch_size)\n    semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'rmse')\n    print('train rmse %f' % train_ls[-1])\n    # apply the network to the test set\n    preds = net(torch.from_numpy(test_features).float()).data.numpy()\n    # reformat it for export to Kaggle\n    sub['time_to_eruption'] = preds\n    sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_and_pred(train_features, test_features, train_labels, data,\n               num_epochs, lr, batch_size)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}